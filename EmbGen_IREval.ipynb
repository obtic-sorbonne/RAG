{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a975e486-3959-4156-a3b4-652a664be1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b2795-2f67-4821-837e-6ae9f7602337",
   "metadata": {},
   "source": [
    "# Embedding generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d918c5-a2ee-4099-9195-997b64b4331f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 30 files:   0%|                                                                        | 0/30 [00:00<?, ?it/s]C:\\Users\\EC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\EC\\.cache\\huggingface\\hub\\models--BAAI--bge-m3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 30 files: 100%|███████████████████████████████████████████████████████████████| 30/30 [01:30<00:00,  3.02s/it]\n",
      "C:\\Users\\EC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Embedding model\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "model = BGEM3FlagModel('BAAI/bge-m3',\n",
    "                       use_fp16=False) # Setting use_fp16 to True speeds up computation with a slight performance degradation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc4cd06-cd78-4129-92d6-d7fc4873f63c",
   "metadata": {},
   "source": [
    "## Reading pickle from the QuestGen notebook with the questions and the subset of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c72d4-a5a1-408f-ae6f-578537bf4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This are the 3448 using as a test\n",
    "meds = pd.read_pickle(\"./meds_3448.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfd9c529-f9e6-40ba-a675-cb6c0104ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We pull apart the questions in other set\n",
    "preguntas = meds[['id', 'pagina','Pregunta']][meds.Pregunta != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fbeb4d-f789-4712-ba69-b0c05225724e",
   "metadata": {},
   "source": [
    "## Generating Sparse Embedding (Lexical Weight), Dense y Multi-Vector (ColBERT) embeddings for every question and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc020b6-a1a5-4f84-a644-23c9842e3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation over texts\n",
    "text_embs = []\n",
    "for i in tqdm(range(len(meds))):\n",
    "    try:\n",
    "        text_embs.append(model.encode(meds.texto[i].lower(),\n",
    "                                      batch_size=12,\n",
    "                                      max_length=8192, # If you don't need such a long length, you can set a smaller value to speed up the encoding process.\n",
    "                                      return_dense=True, return_sparse=True, return_colbert_vecs=True))\n",
    "    except:\n",
    "        text_embs.append('NoInfo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0187b12-d02d-43ac-bec4-21ddba7f7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Appending the embeddings as a column\n",
    "meds['3Embs'] = text_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7678e78-af59-40f9-bd65-2f1da0c2a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation over questions\n",
    "preg_embs = []\n",
    "for i in tqdm(preguntas.Pregunta):\n",
    "    try:\n",
    "        preg_embs.append(model.encode(i.lower(),\n",
    "                                      batch_size=12,\n",
    "                                      max_length=8192, # If you don't need such a long length, you can set a smaller value to speed up the encoding process.\n",
    "                                      return_dense=True, return_sparse=True, return_colbert_vecs=True))\n",
    "    except:\n",
    "        preg_embs.append('NoInfo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48cc14-4964-4a14-a59c-27724215389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Appending the embeddings as a column\n",
    "preguntas['3Embs'] = preg_embs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b2b9c-55c6-4858-b38e-aa6bfff7ad2a",
   "metadata": {},
   "source": [
    "# Retriever\n",
    "\n",
    "\n",
    "For the 65 generated questions and the 3448 texts we are going to use the 3 different scores provided by BM3 to retrieve and compare their performance:\n",
    "\n",
    "* Sparse Embedding (Lexical Weight) -> model.compute_lexical_matching_score\n",
    "* Multi-Vector (ColBERT) -> model.colbert_score\n",
    "* Dense -> dot product\n",
    "* sparse+dense\n",
    "* sparse+dense+colbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf311a8-42b3-4355-a0a8-9ff577c84485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 64/64 [1:20:05<00:00, 75.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# Computing the 3 embeddings and performing the scores\n",
    "ids_lexic = []\n",
    "ids_dense = []\n",
    "ids_colbe = []\n",
    "ids_recup_lex_den = []\n",
    "ids_recup_lex_den_col = []\n",
    "for i in tqdm(range(len(preguntas.Pregunta))):## corriendo en las preguntas\n",
    "    lexic_d = []\n",
    "    dense_d = []\n",
    "    colbe_d = []\n",
    "    lex_den_d = []\n",
    "    lex_den_col_d = []\n",
    "    for j in range(len(meds.texto)): ## corriendo en los contextos\n",
    "        try:\n",
    "            lex_score = model.compute_lexical_matching_score(preguntas['3Embs'][i]['lexical_weights'], meds['3Embs'][j]['lexical_weights'])\n",
    "            dense_score = preguntas['3Embs'][i]['dense_vecs'] @ meds['3Embs'][j]['dense_vecs'].T\n",
    "            colb_score = model.colbert_score(preguntas['3Embs'][i]['colbert_vecs'], meds['3Embs'][j]['colbert_vecs'])\n",
    "            lex_dense = lex_score + dense_score\n",
    "            lex_dense_colb = colb_score + lex_score + dense_score\n",
    "            id = str(meds.id[j])+ str(meds.pagina[j])\n",
    "            lexic_d.append((lex_score,id))\n",
    "            dense_d.append((dense_score,id))\n",
    "            colbe_d.append((colb_score,id))\n",
    "            lex_den_d.append((lex_dense,id))\n",
    "            lex_den_col_d.append((lex_dense_colb,id))\n",
    "        except: ## Agregamos un cero porque como es el máximo no tenemos bronca\n",
    "            lexic_d.append(0)\n",
    "            dense_d.append(0)\n",
    "            colbe_d.append(0)\n",
    "            lex_den_d.append(0)\n",
    "            lex_den_col_d.append(0)\n",
    "        ## Como es el máximo por eso el reverse = True    \n",
    "        lexic_d.sort(reverse = True, key = lambda x: x[0])\n",
    "        dense_d.sort(reverse = True, key = lambda x: x[0])\n",
    "        colbe_d.sort(reverse = True, key = lambda x: x[0])\n",
    "        lex_den_d.sort(reverse = True, key = lambda x: x[0])\n",
    "        lex_den_col_d.sort(reverse = True, key = lambda x: x[0])\n",
    "    ##Añadimos ya los ids recuperados\n",
    "    ids_lexic.append(([k[1] for k in lexic_d[0:10]]))\n",
    "    ids_dense.append(([k[1] for k in dense_d[0:10]]))\n",
    "    ids_colbe.append(([k[1] for k in colbe_d[0:10]]))\n",
    "    ids_recup_lex_den.append(([k[1] for k in lex_den_d[0:10]]))\n",
    "    ids_recup_lex_den_col.append(([k[1] for k in lex_den_col_d[0:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05678ec7-c170-46dd-aa6a-1c734a672ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_1 = preguntas[['id', 'pagina', 'Pregunta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f9b18-d6ad-468a-8a5c-02185f07e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_1['ids_lexic'] = ids_lexic\n",
    "preguntas_1['ids_dense'] = ids_dense\n",
    "preguntas_1['ids_colbe'] = ids_colbe\n",
    "preguntas_1['ids_recup_lex_den'] = ids_recup_lex_den\n",
    "preguntas_1['ids_recup_lex_den_col'] = ids_recup_lex_den_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b00f139-3b3c-4a23-a6b8-cee3d1780d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas_1.to_pickle('../Archivos/65q_results_3embs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3b356d-e2cf-40b6-a21e-b025a632677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas1 = pd.read_pickle('../Archivos/65q_results_3embs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3ce0a00-ce1d-470a-ab8d-413e5a3b287c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pagina</th>\n",
       "      <th>Pregunta</th>\n",
       "      <th>ids_lexic</th>\n",
       "      <th>ids_dense</th>\n",
       "      <th>ids_colbe</th>\n",
       "      <th>ids_recup_lex_den</th>\n",
       "      <th>ids_recup_lex_den_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1025126</td>\n",
       "      <td>PAG_00000029</td>\n",
       "      <td>Quel est le but ultime de l'auteur dans ces le...</td>\n",
       "      <td>[1025126PAG_00000140, 5400519PAG_00000211, 102...</td>\n",
       "      <td>[1025126PAG_00000019, 1025126PAG_00000040, 102...</td>\n",
       "      <td>[1025126PAG_00000019, 1025126PAG_00000049, 102...</td>\n",
       "      <td>[1025126PAG_00000040, 1025126PAG_00000019, 102...</td>\n",
       "      <td>[1025126PAG_00000019, 1025126PAG_00000040, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1025126</td>\n",
       "      <td>PAG_00000042</td>\n",
       "      <td>Qu'est-ce qui est à l'évidence de laquelle per...</td>\n",
       "      <td>[1025126PAG_00000042, 1025134PAG_00000082, 540...</td>\n",
       "      <td>[5400517PAG_00000082, 1025168PAG_00000017, 102...</td>\n",
       "      <td>[1025126PAG_00000095, 1025126PAG_00000042, 540...</td>\n",
       "      <td>[1025126PAG_00000042, 1025168PAG_00000017, 540...</td>\n",
       "      <td>[1025126PAG_00000042, 1025126PAG_00000095, 540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1025126</td>\n",
       "      <td>PAG_00000102</td>\n",
       "      <td>?</td>\n",
       "      <td>[5400513PAG_00000061, 1025165PAG_00000022, 540...</td>\n",
       "      <td>[5400511PAG_00000139, 5400511PAG_00000004, 540...</td>\n",
       "      <td>[5400511PAG_00000004, 5400511PAG_00000139, 540...</td>\n",
       "      <td>[5400511PAG_00000139, 5400511PAG_00000004, 540...</td>\n",
       "      <td>[5400511PAG_00000004, 5400511PAG_00000139, 540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1025126</td>\n",
       "      <td>PAG_00000120</td>\n",
       "      <td>Quel est le poids de l'auteur à midi le mercre...</td>\n",
       "      <td>[1025126PAG_00000126, 1025126PAG_00000121, 102...</td>\n",
       "      <td>[1025126PAG_00000122, 1025126PAG_00000124, 102...</td>\n",
       "      <td>[1025126PAG_00000120, 1025126PAG_00000121, 102...</td>\n",
       "      <td>[1025126PAG_00000122, 1025126PAG_00000121, 102...</td>\n",
       "      <td>[1025126PAG_00000122, 1025126PAG_00000121, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1025126</td>\n",
       "      <td>PAG_00000131</td>\n",
       "      <td>Quel est le poids total de l'individu à midi, ...</td>\n",
       "      <td>[1025126PAG_00000111, 1025126PAG_00000109, 102...</td>\n",
       "      <td>[1025126PAG_00000118, 1025126PAG_00000113, 102...</td>\n",
       "      <td>[1025126PAG_00000118, 1025126PAG_00000114, 102...</td>\n",
       "      <td>[1025126PAG_00000114, 1025126PAG_00000111, 102...</td>\n",
       "      <td>[1025126PAG_00000118, 1025126PAG_00000114, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5400517</td>\n",
       "      <td>PAG_00000308</td>\n",
       "      <td>Pourquoi le système osseux est-il souvent oubl...</td>\n",
       "      <td>[5400517PAG_00000308, 5400517PAG_00000309, 540...</td>\n",
       "      <td>[5400517PAG_00000308, 5400517PAG_00000309, 540...</td>\n",
       "      <td>[5400517PAG_00000308, 5400519PAG_00000012, 540...</td>\n",
       "      <td>[5400517PAG_00000308, 5400517PAG_00000309, 540...</td>\n",
       "      <td>[5400517PAG_00000308, 5400517PAG_00000309, 540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5400517</td>\n",
       "      <td>PAG_00000373</td>\n",
       "      <td>Quel est le rôle de la nature selon l'auteur, ...</td>\n",
       "      <td>[1025133PAG_00000063, 5400517PAG_00000051, 540...</td>\n",
       "      <td>[5400517PAG_00000379, 5400517PAG_00000051, 540...</td>\n",
       "      <td>[5400517PAG_00000379, 5400517PAG_00000434, 540...</td>\n",
       "      <td>[5400517PAG_00000379, 5400517PAG_00000051, 540...</td>\n",
       "      <td>[5400517PAG_00000379, 5400517PAG_00000434, 540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5400517</td>\n",
       "      <td>PAG_00000374</td>\n",
       "      <td>?</td>\n",
       "      <td>[5400513PAG_00000061, 1025165PAG_00000022, 540...</td>\n",
       "      <td>[5400511PAG_00000139, 5400511PAG_00000004, 540...</td>\n",
       "      <td>[5400511PAG_00000004, 5400511PAG_00000139, 540...</td>\n",
       "      <td>[5400511PAG_00000139, 5400511PAG_00000004, 540...</td>\n",
       "      <td>[5400511PAG_00000004, 5400511PAG_00000139, 540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5400519</td>\n",
       "      <td>PAG_00000042</td>\n",
       "      <td>Quel est le but de l'application d'une autre a...</td>\n",
       "      <td>[5400519PAG_00000042, 5400519PAG_00000049, 540...</td>\n",
       "      <td>[5400519PAG_00000042, 5400519PAG_00000041, 540...</td>\n",
       "      <td>[5400519PAG_00000042, 5400519PAG_00000047, 540...</td>\n",
       "      <td>[5400519PAG_00000042, 5400519PAG_00000051, 540...</td>\n",
       "      <td>[5400519PAG_00000042, 5400519PAG_00000047, 540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5400519</td>\n",
       "      <td>PAG_00000193</td>\n",
       "      <td>Quel est le rôle que joue la fistule dans l'op...</td>\n",
       "      <td>[5400519PAG_00000193, 5400519PAG_00000198, 540...</td>\n",
       "      <td>[5400519PAG_00000198, 5400519PAG_00000193, 540...</td>\n",
       "      <td>[5400519PAG_00000193, 5400519PAG_00000198, 540...</td>\n",
       "      <td>[5400519PAG_00000193, 5400519PAG_00000198, 540...</td>\n",
       "      <td>[5400519PAG_00000193, 5400519PAG_00000198, 540...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id        pagina                                           Pregunta  \\\n",
       "0   1025126  PAG_00000029  Quel est le but ultime de l'auteur dans ces le...   \n",
       "1   1025126  PAG_00000042  Qu'est-ce qui est à l'évidence de laquelle per...   \n",
       "2   1025126  PAG_00000102                                                  ?   \n",
       "3   1025126  PAG_00000120  Quel est le poids de l'auteur à midi le mercre...   \n",
       "4   1025126  PAG_00000131  Quel est le poids total de l'individu à midi, ...   \n",
       "..      ...           ...                                                ...   \n",
       "59  5400517  PAG_00000308  Pourquoi le système osseux est-il souvent oubl...   \n",
       "60  5400517  PAG_00000373  Quel est le rôle de la nature selon l'auteur, ...   \n",
       "61  5400517  PAG_00000374                                                  ?   \n",
       "62  5400519  PAG_00000042  Quel est le but de l'application d'une autre a...   \n",
       "63  5400519  PAG_00000193  Quel est le rôle que joue la fistule dans l'op...   \n",
       "\n",
       "                                            ids_lexic  \\\n",
       "0   [1025126PAG_00000140, 5400519PAG_00000211, 102...   \n",
       "1   [1025126PAG_00000042, 1025134PAG_00000082, 540...   \n",
       "2   [5400513PAG_00000061, 1025165PAG_00000022, 540...   \n",
       "3   [1025126PAG_00000126, 1025126PAG_00000121, 102...   \n",
       "4   [1025126PAG_00000111, 1025126PAG_00000109, 102...   \n",
       "..                                                ...   \n",
       "59  [5400517PAG_00000308, 5400517PAG_00000309, 540...   \n",
       "60  [1025133PAG_00000063, 5400517PAG_00000051, 540...   \n",
       "61  [5400513PAG_00000061, 1025165PAG_00000022, 540...   \n",
       "62  [5400519PAG_00000042, 5400519PAG_00000049, 540...   \n",
       "63  [5400519PAG_00000193, 5400519PAG_00000198, 540...   \n",
       "\n",
       "                                            ids_dense  \\\n",
       "0   [1025126PAG_00000019, 1025126PAG_00000040, 102...   \n",
       "1   [5400517PAG_00000082, 1025168PAG_00000017, 102...   \n",
       "2   [5400511PAG_00000139, 5400511PAG_00000004, 540...   \n",
       "3   [1025126PAG_00000122, 1025126PAG_00000124, 102...   \n",
       "4   [1025126PAG_00000118, 1025126PAG_00000113, 102...   \n",
       "..                                                ...   \n",
       "59  [5400517PAG_00000308, 5400517PAG_00000309, 540...   \n",
       "60  [5400517PAG_00000379, 5400517PAG_00000051, 540...   \n",
       "61  [5400511PAG_00000139, 5400511PAG_00000004, 540...   \n",
       "62  [5400519PAG_00000042, 5400519PAG_00000041, 540...   \n",
       "63  [5400519PAG_00000198, 5400519PAG_00000193, 540...   \n",
       "\n",
       "                                            ids_colbe  \\\n",
       "0   [1025126PAG_00000019, 1025126PAG_00000049, 102...   \n",
       "1   [1025126PAG_00000095, 1025126PAG_00000042, 540...   \n",
       "2   [5400511PAG_00000004, 5400511PAG_00000139, 540...   \n",
       "3   [1025126PAG_00000120, 1025126PAG_00000121, 102...   \n",
       "4   [1025126PAG_00000118, 1025126PAG_00000114, 102...   \n",
       "..                                                ...   \n",
       "59  [5400517PAG_00000308, 5400519PAG_00000012, 540...   \n",
       "60  [5400517PAG_00000379, 5400517PAG_00000434, 540...   \n",
       "61  [5400511PAG_00000004, 5400511PAG_00000139, 540...   \n",
       "62  [5400519PAG_00000042, 5400519PAG_00000047, 540...   \n",
       "63  [5400519PAG_00000193, 5400519PAG_00000198, 540...   \n",
       "\n",
       "                                    ids_recup_lex_den  \\\n",
       "0   [1025126PAG_00000040, 1025126PAG_00000019, 102...   \n",
       "1   [1025126PAG_00000042, 1025168PAG_00000017, 540...   \n",
       "2   [5400511PAG_00000139, 5400511PAG_00000004, 540...   \n",
       "3   [1025126PAG_00000122, 1025126PAG_00000121, 102...   \n",
       "4   [1025126PAG_00000114, 1025126PAG_00000111, 102...   \n",
       "..                                                ...   \n",
       "59  [5400517PAG_00000308, 5400517PAG_00000309, 540...   \n",
       "60  [5400517PAG_00000379, 5400517PAG_00000051, 540...   \n",
       "61  [5400511PAG_00000139, 5400511PAG_00000004, 540...   \n",
       "62  [5400519PAG_00000042, 5400519PAG_00000051, 540...   \n",
       "63  [5400519PAG_00000193, 5400519PAG_00000198, 540...   \n",
       "\n",
       "                                ids_recup_lex_den_col  \n",
       "0   [1025126PAG_00000019, 1025126PAG_00000040, 102...  \n",
       "1   [1025126PAG_00000042, 1025126PAG_00000095, 540...  \n",
       "2   [5400511PAG_00000004, 5400511PAG_00000139, 540...  \n",
       "3   [1025126PAG_00000122, 1025126PAG_00000121, 102...  \n",
       "4   [1025126PAG_00000118, 1025126PAG_00000114, 102...  \n",
       "..                                                ...  \n",
       "59  [5400517PAG_00000308, 5400517PAG_00000309, 540...  \n",
       "60  [5400517PAG_00000379, 5400517PAG_00000434, 540...  \n",
       "61  [5400511PAG_00000004, 5400511PAG_00000139, 540...  \n",
       "62  [5400519PAG_00000042, 5400519PAG_00000047, 540...  \n",
       "63  [5400519PAG_00000193, 5400519PAG_00000198, 540...  \n",
       "\n",
       "[64 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preguntas1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f79ca1-2921-4af6-8b76-2738d1e391fb",
   "metadata": {},
   "source": [
    "# IR Evaluation\n",
    "\n",
    "Checking weter the first retrieved document is the correct one, or if is not, if the correct document is on the set and in which place.\n",
    "We need to remember that 65 questions were generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd3077-e69a-4ff2-a3f7-c124fe1d6ff5",
   "metadata": {},
   "source": [
    "## Lexical embeddings Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3471a4e6-53d1-42b3-86a7-80e25238a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_lexic = []\n",
    "for i in range(len(preguntas1)):\n",
    "    correcto = str(preguntas1.id[i]) + str(preguntas1.pagina[i])\n",
    "    ids = preguntas1.ids_lexic[i]\n",
    "    try:\n",
    "        ev_lexic.append(ids.index(correcto)+1) ## buscamos si esta dentro del conjunto y le sumamos 1 (por aquello de la cuenta en 0)\n",
    "    except:\n",
    "        ev_lexic.append('NA') ## Si no está el indice, no lo recupero, contamos los 1, son buenos, y buscamos la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca9002d8-b696-4d24-8954-e0382816de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas1['Eval_Lex'] = ev_lexic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89424571-b26d-435f-ad58-954b13a8d84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#times that the document is in 1 place: 30\n",
      "#times that the document is in 2 place: 5\n",
      "#times that the document is in 3 place: 4\n",
      "#times that the document is in 4 place: 3\n",
      "#times that the document is in NA place: 16\n",
      "#times that the document is in 6 place: 3\n",
      "#times that the document is in 8 place: 2\n",
      "#times that the document is in 10 place: 1\n"
     ]
    }
   ],
   "source": [
    "for i in set(ev_lexic):\n",
    "    print(f'#times that the document is in {i} place: {ev_lexic.count(i)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76cbef4-04a4-4941-9561-dff0fcd17db2",
   "metadata": {},
   "source": [
    "# Dense embeddings Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d2b515c-ee98-48f2-b8fd-5a6efc8be431",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_dense = []\n",
    "for i in range(len(preguntas1)):\n",
    "    correcto = str(preguntas1.id[i]) + str(preguntas1.pagina[i])\n",
    "    ids = preguntas1.ids_dense[i]\n",
    "    try:\n",
    "        ev_dense.append(ids.index(correcto)+1) ## buscamos si esta dentro del conjunto y le sumamos 1 (por aquello de la cuenta en 0)\n",
    "    except:\n",
    "        ev_dense.append('NA') ## Si no está el indice, no lo recupero, contamos los 1, son buenos, y buscamos la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403027af-d24b-4a0d-883d-d861f3e577d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#times that the document is in 1 place: 24\n",
      "#times that the document is in 2 place: 8\n",
      "#times that the document is in 3 place: 5\n",
      "#times that the document is in 4 place: 3\n",
      "#times that the document is in 5 place: 3\n",
      "#times that the document is in NA place: 16\n",
      "#times that the document is in 6 place: 3\n",
      "#times that the document is in 8 place: 1\n",
      "#times that the document is in 9 place: 1\n"
     ]
    }
   ],
   "source": [
    "for i in set(ev_dense):\n",
    "    print(f'#times that the document is in {i} place: {ev_dense.count(i)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "721095cf-c1eb-4d8c-bb3f-4f07d005282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas1['Eval_Dense'] = ev_dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0557cc61-cce7-42ab-b850-032897914994",
   "metadata": {},
   "source": [
    "# Colbert Embeddings Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "574df5c8-69e3-4553-9d3d-7696dca4050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_colb = []\n",
    "for i in range(len(preguntas1)):\n",
    "    correcto = str(preguntas1.id[i]) + str(preguntas1.pagina[i])\n",
    "    ids = preguntas1.ids_colbe[i]\n",
    "    try:\n",
    "        ev_colb.append(ids.index(correcto)+1) ## buscamos si esta dentro del conjunto y le sumamos 1 (por aquello de la cuenta en 0)\n",
    "    except:\n",
    "        ev_colb.append('NA') ## Si no está el indice, no lo recupero, contamos los 1, son buenos, y buscamos la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cb725ec-0fc6-4cb1-a717-1bd8e1540269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#times that the document is in 1 place: 30\n",
      "#times that the document is in 2 place: 6\n",
      "#times that the document is in 3 place: 6\n",
      "#times that the document is in 4 place: 3\n",
      "#times that the document is in NA place: 15\n",
      "#times that the document is in 7 place: 1\n",
      "#times that the document is in 6 place: 1\n",
      "#times that the document is in 9 place: 1\n",
      "#times that the document is in 8 place: 1\n"
     ]
    }
   ],
   "source": [
    "for i in set(ev_colb):\n",
    "    print(f'Veces que se encontró en lugar {i}: {ev_colb.count(i)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e031baf3-9dd4-453d-a7e3-d87b317677a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas1['Eval_Colb'] = ev_colb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31da94b-cb46-4a68-8189-e84f92d4f81d",
   "metadata": {},
   "source": [
    "# Sparse + Dense score Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce757c4e-4f9a-44ed-bf94-01ffbcab7105",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_2comb = []\n",
    "for i in range(len(preguntas1)):\n",
    "    correcto = str(preguntas1.id[i]) + str(preguntas1.pagina[i])\n",
    "    ids = preguntas1.ids_recup_lex_den[i]\n",
    "    try:\n",
    "        ev_2comb.append(ids.index(correcto)+1) ## buscamos si esta dentro del conjunto y le sumamos 1 (por aquello de la cuenta en 0)\n",
    "    except:\n",
    "        ev_2comb.append('NA') ## Si no está el indice, no lo recupero, contamos los 1, son buenos, y buscamos la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dcab8f1-fd3d-478f-9441-c97eafd723dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#times that the document is in 1 place: 32\n",
      "#times that the document is in 2 place: 12\n",
      "#times that the document is in 3 place: 3\n",
      "#times that the document is in NA place: 16\n",
      "#times that the document is in 6 place: 1\n"
     ]
    }
   ],
   "source": [
    "for i in set(ev_2comb):\n",
    "    print(f'Veces que se encontró en lugar {i}: {ev_2comb.count(i)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9535fb84-362d-4464-99b3-9ae3ed24e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas1['Eval_Lex_Dense'] = ev_2comb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e356e-71f0-4130-aa87-a488205b1237",
   "metadata": {},
   "source": [
    "# Evaluacion 3 embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c522697-7e64-4f79-83eb-16e06bf27afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_3embs = []\n",
    "for i in range(len(preguntas1)):\n",
    "    correcto = str(preguntas1.id[i]) + str(preguntas1.pagina[i])\n",
    "    ids = preguntas1.ids_recup_lex_den_col[i]\n",
    "    try:\n",
    "        ev_3embs.append(ids.index(correcto)+1) ## buscamos si esta dentro del conjunto y le sumamos 1 (por aquello de la cuenta en 0)\n",
    "    except:\n",
    "        ev_3embs.append('NA') ## Si no está el indice, no lo recupero, contamos los 1, son buenos, y buscamos la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d88e281-8d9e-4bbb-b8a0-1514fa842b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#times that the document is in 1 place: 31\n",
      "#times that the document is in 2 place: 13\n",
      "#times that the document is in 3 place: 3\n",
      "#times that the document is in NA place: 15\n",
      "#times that the document is in 6 place: 1\n",
      "#times that the document is in 10 place: 1\n"
     ]
    }
   ],
   "source": [
    "for i in set(ev_3embs):\n",
    "    print(f'Veces que se encontró en lugar {i}: {ev_3embs.count(i)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10e6211d-a789-4b34-89ba-a86892c89956",
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas1['Eval_3embs'] = ev_3embs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
